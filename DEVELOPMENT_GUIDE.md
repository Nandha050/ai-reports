# ReportMind AI - Development Progress & Setup Guide

**Last Updated:** January 6, 2026  
**Status:** ðŸŸ¢ Core Features Implemented & Ready for Testing

---

## ðŸ“‹ What's Been Implemented

### âœ… Phase 1: Backend Foundation & Architecture
- **Express + TypeScript** server with proper structure
- **MongoDB** connection and model definitions
- **Redis + BullMQ** for async job processing
- **Azure Document Intelligence** integration for PDF parsing
- **Error handling middleware** with graceful error propagation
- **Optional authentication middleware** for user context

### âœ… Phase 2: Multi-Agent LangGraph Pipeline
All 9 agents fully implemented with logic:

1. **IngestionAgent** - Parses PDFs using Azure DI, extracts pages and tables
2. **StructureUnderstandingAgent** - Identifies document sections and structure
3. **DomainInferenceAgent** - Detects domains (finance, ESG, operations, risk, market)
4. **MetricDiscoveryAgent** - Finds quantitative metrics and numeric values
5. **TableExtractionAgent** - Processes and enriches table data with headers/rows
6. **NarrativeExtractionAgent** - Extracts narrative content with sentiment analysis
7. **FootnoteAgent** - Identifies footnotes and references with metric linkage
8. **ValidationAgent** - Validates extracted data and calculates confidence scores
9. **InsightAgent** - Generates insights and summary metrics

### âœ… Phase 3: API Endpoints
Fully implemented Report API endpoints:

```
POST   /api/v1/reports/upload          â†’ Upload PDF (returns 202 Accepted)
GET    /api/v1/reports                 â†’ List all reports (with pagination)
GET    /api/v1/reports/:reportId       â†’ Get report with extracted data
GET    /api/v1/reports/:reportId/status â†’ Check processing status
DELETE /api/v1/reports/:reportId       â†’ Delete report
```

### âœ… Phase 4: Data Persistence
- Agents remain **stateless** (no DB writes)
- **PersistenceService** runs post-pipeline
- All extracted data saved to MongoDB collections:
  - DocumentSections
  - Tables
  - Narratives
  - Metrics
  - Footnotes
  - ExtractedValues
  - UnclassifiedData

### âœ… Phase 5: Error Handling & Reliability
- **Worker error handling** with detailed logging
- **Retry logic** configuration (max 3 attempts)
- **Job failure recovery** - reports marked as FAILED with error details
- **Comprehensive logging** at each pipeline stage

---

## ðŸš€ Getting Started

### Prerequisites
- Node.js 18+
- MongoDB 5.0+
- Redis 6.0+
- Azure Document Intelligence resource (with endpoint & key)

### Environment Setup

Create `.env` file in `backend/` directory:

```bash
# Server
NODE_ENV=development
PORT=3000

# MongoDB
MONGODB_URI=mongodb://localhost:27017/reportmind-ai

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# Azure Document Intelligence
AZURE_DI_ENDPOINT=https://<region>.api.cognitive.microsoft.com/
AZURE_DI_KEY=<your-key>

# Optional
LOG_LEVEL=debug
```

### Installation & Running

```bash
# Install dependencies
cd backend
npm install

# Development mode (with auto-reload)
npm run dev

# Build for production
npm run build

# Production mode
npm start
```

The backend will start on `http://localhost:3000`

---

## ðŸ“Š API Usage Examples

### 1. Upload a PDF Report

```bash
curl -X POST http://localhost:3000/api/v1/reports/upload \
  -F "file=@report.pdf" \
  -H "Authorization: Bearer userid:orgid:email@example.com"
```

**Response (202 Accepted):**
```json
{
  "reportId": "report-1704564000000",
  "jobId": "job-123",
  "status": "PROCESSING",
  "fileName": "report.pdf"
}
```

### 2. Check Processing Status

```bash
curl http://localhost:3000/api/v1/reports/report-1704564000000/status
```

**Response:**
```json
{
  "reportId": "report-1704564000000",
  "status": "COMPLETED",
  "fileName": "report.pdf",
  "createdAt": "2026-01-06T10:00:00Z"
}
```

### 3. Retrieve Extracted Data

```bash
curl http://localhost:3000/api/v1/reports/report-1704564000000
```

**Response:**
```json
{
  "report": {
    "_id": "report-1704564000000",
    "fileName": "report.pdf",
    "status": "COMPLETED",
    "totalPages": 45,
    "detectedDomains": ["finance", "esg"]
  },
  "summary": {
    "sectionsCount": 12,
    "tablesCount": 8,
    "metricsCount": 45,
    "narrativesCount": 15
  },
  "data": {
    "sections": [...],
    "tables": [...],
    "metrics": [...],
    "narratives": [...]
  }
}
```

### 4. List All Reports

```bash
curl "http://localhost:3000/api/v1/reports?page=1&limit=10&status=COMPLETED"
```

### 5. Delete a Report

```bash
curl -X DELETE http://localhost:3000/api/v1/reports/report-1704564000000
```

---

## ðŸ” Pipeline Execution Flow

```
PDF Upload
    â†“
Express API validates & creates report record
    â†“
BullMQ enqueues job to Redis
    â†“
Worker picks up job
    â†“
[LANGGRAPH PIPELINE]
    â”œâ”€â†’ IngestionAgent (Parse PDF with Azure DI)
    â”œâ”€â†’ StructureUnderstandingAgent (Identify sections)
    â”œâ”€â†’ DomainInferenceAgent (Detect domains)
    â”œâ”€â†’ MetricDiscoveryAgent (Find metrics)
    â”œâ”€â†’ TableExtractionAgent (Process tables)
    â”œâ”€â†’ NarrativeExtractionAgent (Extract text)
    â”œâ”€â†’ FootnoteAgent (Find references)
    â”œâ”€â†’ ValidationAgent (Validate & score)
    â””â”€â†’ InsightAgent (Generate insights)
    â†“
PersistenceService saves to MongoDB
    â†“
Report status updated to COMPLETED
    â†“
API returns extracted data to client
```

---

## ðŸ“ Agent Details

### IngestionAgent
**Input:** File path  
**Output:** Pages (with text), Tables (structured cells)  
**Process:** Uses Azure Document Intelligence prebuilt-layout model

### StructureUnderstandingAgent
**Input:** Pages (raw text)  
**Output:** Sections (heading + content)  
**Process:** Detects uppercase headings and organizes content hierarchically

### DomainInferenceAgent
**Input:** Pages + Sections  
**Output:** Top 3 domains by relevance score  
**Process:** Keyword matching against domain signatures

**Detected Domains:**
- finance (revenue, profit, EBITDA, margins)
- esg (carbon, sustainability, environmental)
- operations (efficiency, capacity, supply chain)
- risk (compliance, audit, threats)
- market (competitive, customer, sales)

### MetricDiscoveryAgent
**Input:** Pages + Tables  
**Output:** Discovered metrics with values and context  
**Process:** Regex pattern matching for key metrics + table cell extraction

### TableExtractionAgent
**Input:** Raw tables (cells from Azure DI)  
**Output:** Enriched tables with headers and row data  
**Process:** Builds grid, detects headers, flags numeric data

### NarrativeExtractionAgent
**Input:** Sections + Pages  
**Output:** Narrative blocks with sentiment  
**Process:** Sentiment analysis using keyword detection

### FootnoteAgent
**Input:** All pages + Metrics  
**Output:** Footnotes with linked metrics  
**Process:** Pattern matching for [1], * formats, and reference linking

### ValidationAgent
**Input:** All extracted data  
**Output:** Validation issues + confidence score (0-1)  
**Process:** Checks for completeness and flags missing data

**Deductions:**
- No pages: -0.30
- Empty table: -0.05 each
- No metrics: -0.10
- Unknown domain: -0.15
- Minimal content: -0.02 each

### InsightAgent
**Input:** All extracted data  
**Output:** 5-7 actionable insights  
**Process:** Generates summaries, trends, and anomalies

---

## ðŸ” Authentication

### Current Implementation
Simple Bearer token format for development:

```
Authorization: Bearer userid:orgid:email@example.com
```

**In Production, You Should:**
1. Implement JWT token generation in Auth API
2. Validate JWT signatures
3. Add organization & permission checks
4. Implement rate limiting per user/org

Example setup:
```typescript
// Generate JWT in login endpoint
const token = jwt.sign(
  { userId, orgId, email, roles: ['user'] },
  process.env.JWT_SECRET,
  { expiresIn: '24h' }
);

// Validate in authMiddleware
const decoded = jwt.verify(token, process.env.JWT_SECRET);
```

---

## ðŸ“Š Database Models

### Report
```
{
  _id: String,
  fileName: String,
  fileUrl: String,
  status: "UPLOADED" | "PROCESSING" | "COMPLETED" | "FAILED",
  totalPages: Number,
  detectedDomains: [String],
  createdAt: Date
}
```

### DocumentSection
```
{
  reportId: String,
  pageNumber: Number,
  heading: String,
  content: String,
  depth: Number
}
```

### Table
```
{
  reportId: String,
  pageNumber: Number,
  rowCount: Number,
  columnCount: Number,
  headers: [String],
  rows: [[String]],
  summary: String
}
```

### Metric
```
{
  reportId: String,
  name: String,
  value: String | Number,
  unit: String,
  pageNumber: Number,
  context: String
}
```

---

## ðŸ§ª Testing the Pipeline

### Quick Test with Sample PDF

1. **Upload a test PDF:**
```bash
curl -X POST http://localhost:3000/api/v1/reports/upload \
  -F "file=@sample.pdf" \
  --output response.json

cat response.json | jq '.reportId'
```

2. **Poll for completion:**
```bash
# Check status (should be PROCESSING initially)
curl http://localhost:3000/api/v1/reports/report-xxx/status

# Wait 10-30 seconds for processing
# Check again until status is COMPLETED
```

3. **Retrieve results:**
```bash
curl http://localhost:3000/api/v1/reports/report-xxx | jq '.'
```

### Expected Output
```json
{
  "report": {
    "status": "COMPLETED",
    "totalPages": 15,
    "detectedDomains": ["finance", "esg"]
  },
  "summary": {
    "sectionsCount": 8,
    "tablesCount": 5,
    "metricsCount": 32,
    "narrativesCount": 12
  }
}
```

---

## ðŸ” Monitoring & Debugging

### View Worker Logs
```bash
# Terminal where backend is running should show detailed logs:
ðŸš€ Starting report processing job...
ðŸ“‹ Initial state prepared
ðŸ”„ Executing report graph pipeline...
âœ… IngestionAgent started
ðŸ“Š Azure DI pages: 15
ðŸ—ï¸ StructureUnderstandingAgent analyzing...
âœ… Identified 8 document sections
ðŸ” DomainInferenceAgent inferring...
âœ… Detected domains: finance, esg
...
âœ… Report processing completed successfully
```

### Check Redis Queue
```bash
# Install redis-cli
redis-cli

# View pending jobs
> LLEN bull:report-queue:wait

# View active jobs
> LLEN bull:report-queue:active

# View completed jobs
> LLEN bull:report-queue:completed
```

### Check MongoDB
```bash
# Connect to MongoDB
mongosh reportmind-ai

# View reports
db.reports.find()

# View extracted sections
db.documentsections.find()

# View metrics
db.metrics.find()
```

---

## ðŸš¨ Common Issues & Solutions

### Issue: "Azure DI Endpoint not found"
**Solution:** Ensure `.env` has `AZURE_DI_ENDPOINT` and `AZURE_DI_KEY` set correctly

### Issue: "Connection refused to Redis"
**Solution:** Ensure Redis is running:
```bash
redis-server  # Start Redis if not running
```

### Issue: "No pages extracted"
**Solution:** Verify PDF format is supported by Azure DI (prebuilt-layout model)

### Issue: "Job marked as FAILED"
**Solution:** Check backend console logs for error details, then retry upload

### Issue: "High memory usage"
**Solution:** Reduce worker concurrency or limit job queue size in production

---

## ðŸ“ˆ Performance Optimization

### Currently
- **Concurrency:** 2 jobs per worker
- **Retry:** Up to 3 attempts
- **Lock duration:** 60 seconds per job

### For Scale
1. Increase concurrency (if hardware allows)
2. Use multiple workers across different servers
3. Add job batching for similar reports
4. Implement caching for domain/metric detection

---

## ðŸ”œ Next Steps / TODO

### High Priority
- [ ] Implement real JWT authentication in Auth API
- [ ] Add pagination to data retrieval endpoints
- [ ] Implement dashboard data aggregation endpoint
- [ ] Add report filtering and search
- [ ] Setup production MongoDB and Redis with auth

### Medium Priority
- [ ] Add webhook notifications for job completion
- [ ] Implement organization-level data isolation
- [ ] Add user roles and permissions system
- [ ] Setup logging aggregation (ELK/DataDog)
- [ ] Add performance metrics collection

### Low Priority
- [ ] Add rate limiting per user/API key
- [ ] Implement report version history
- [ ] Add export functionality (PDF, CSV)
- [ ] Frontend dashboard UI
- [ ] API documentation (Swagger/OpenAPI)

---

## ðŸ“š File Structure Reference

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/                 # LangGraph AI agents
â”‚   â”‚   â”œâ”€â”€ base.agent.ts       # Agent type definition
â”‚   â”‚   â”œâ”€â”€ ingestion.agent.ts
â”‚   â”‚   â”œâ”€â”€ structure.agent.ts
â”‚   â”‚   â”œâ”€â”€ domain.agent.ts
â”‚   â”‚   â”œâ”€â”€ metricDiscovery.agent.ts
â”‚   â”‚   â”œâ”€â”€ tableExtraction.agent.ts
â”‚   â”‚   â”œâ”€â”€ narrative.agent.ts
â”‚   â”‚   â”œâ”€â”€ footnote.agent.ts
â”‚   â”‚   â”œâ”€â”€ validation.agent.ts
â”‚   â”‚   â””â”€â”€ insight.agent.ts
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ reports/
â”‚   â”‚       â”œâ”€â”€ report.controller.ts    # API endpoints
â”‚   â”‚       â””â”€â”€ report.routes.ts
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ db.ts               # MongoDB connection
â”‚   â”‚   â””â”€â”€ redis.ts            # Redis connection
â”‚   â”œâ”€â”€ graph/
â”‚   â”‚   â”œâ”€â”€ graph.state.ts      # State definitions
â”‚   â”‚   â””â”€â”€ report.graph.ts     # LangGraph orchestration
â”‚   â”œâ”€â”€ middlewares/
â”‚   â”‚   â”œâ”€â”€ auth.middleware.ts
â”‚   â”‚   â””â”€â”€ error.middleware.ts
â”‚   â”œâ”€â”€ models/                 # MongoDB schemas
â”‚   â”œâ”€â”€ queues/
â”‚   â”‚   â””â”€â”€ report.queue.ts     # BullMQ queue
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ azureDocumentIntelligence.service.ts
â”‚   â”‚   â”œâ”€â”€ fileUpload.service.ts
â”‚   â”‚   â””â”€â”€ persistence.service.ts
â”‚   â”œâ”€â”€ workers/
â”‚   â”‚   â””â”€â”€ report.worker.ts    # Job worker
â”‚   â”œâ”€â”€ app.ts                  # Express app setup
â”‚   â””â”€â”€ server.ts               # Server entry point
```

---

## ðŸ’¡ Tips for Contributors

1. **Keep agents pure** - No database writes in agents, only state updates
2. **Add logging** - Use `console.log` with emojis for easy scanning
3. **Type everything** - Use TypeScript interfaces for state shape
4. **Test incrementally** - Upload small PDFs first, then larger ones
5. **Check logs** - Always check terminal logs before assuming errors

---

## ðŸ“ž Support

For issues or questions:
1. Check the console logs for detailed error messages
2. Review this documentation
3. Check MongoDB for data verification
4. Verify environment variables are set correctly

---

**Happy coding! ðŸš€**
